---
layout: post
title: Data Science Bootcamp, Metis - Project_02
---

# Introduction

The goal of the second project of the Data science Bootcamp is to build a linear regression model. The process starts by choosing a website to data scrape from and collect enough information to build the model. Then, data is cleaned and organized. lastly, a model is built and tested. My project aims to build a model that predics the prices of Ford F-150 cars in California.


Picture: proj02_ford_f-150.png

# Steps

## Data Scraping
Data was collected from [Autotrader](http://autotrader.com).

Picture: proj02_site.png

The website uses the zipcode of the area and looks for matches in a given radius. Three zipcodes were used in the search, 94102 (San Francisco), 90071 (Los Angeles) and 92101 (San Diego). This covers north, centeral and south California. For each zipcode, 10 pages worth of listings were scraped with each page containing 100 listings (a total of 1000 listing per zipcode).

The site provides the price, mileage, year, model, color and number of cylinders for each listing.

Picture: proj02_example_listing.png

## Data Cleaning
This step started with a raw dataFrame that needs to be cleaned and organized.

Picture: proj02_raw_df.pnp

First, the extra index column was dropped. Then, 'name' column was divided into two columns, 'Year' and 'Model'. After that, rows with NaNs were droped. Next, duplicates rows were dropped too (there are overlaps in the search areas which indicate possible duplicate listing were scraped).

Looking at the unique values of the 'color' column, there are 13 different colors for the cars listed. I noticed that the 6 most popular colors represent the vast majority of the listings.

Picture: proj02_colors_all.pnp

For this reason, I decided to keep the 6 most popular colors, and assign "other" for the rest of them.

Picture: proj02_colors_some.pnp

At the end of this step, one outlier was deleted, coloms values were converted to their appropriate types.

Now, a ready dataFrame is pickled to be used in creating the model.

Picture: proj02_clean_df.pnp

## Linear Regression Model
To make the process of creating and validating deferent models, I have created a function that takes a dataFrame, computes and prints the cross training and validatoin scores, plot the residual and Q-Q plots, and returns the test set.

The base model was trained on the dataFrame without the catagorical columns ('Model', 'Cylinder' and 'color').

Picture: proj02_df_base_model.pnp

a heat map and a pair plot were created to assest the data.

Picture: proj02_heatmap.pnp

Picture: proj02_pair_plot.pnp

Results for the base model were good.

Picture: proj02_base_model.pnp

Linear Regression model was choosen. Next, I am performing feature engineering trying to come up with a better model.

- Adding dummy variables

Picture: proj02_df_dummy.pnp

Picture: proj02_dummy_model.pnp

- Taking the log of the price

Picture: proj02_log_price_model.pnp

- Performing power trnsformation on price

Picture: proj02_transformed_model

- Adding a column for mileage per year

Picture: proj02_miles/year_model.pnp

- Dropping the 'Mileage' column

Picture: proj02_no_mileage_model.pnp

At the end, the model with adding only the dummy variables was choosing for the final test.
  
# Test and Predictions

The choosen model was tested

Picture: proj02_test.pnp

Here is a comparison between actual and predicted values

Picture: proj02_predictions.pnp

![Top five stations in terms of valume]({{ site.url }}/images/Top_5.png)

![avg_inflow_outflow]({{ site.url }}/images/avg_inflow_outflow.png)

![Average_per_station]({{ site.url }}/images/Average_per_station.png)
